{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "gDuDPSH2KmXF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiY20cvlYKUf",
        "outputId": "52d46d33-108a-408a-964e-d996ef46dcae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  /content/movie_data.zip\n",
            "replace movie_data.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: y\n",
            "  inflating: movie_data.csv          \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/movie_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "SYTRBAFzKmXF",
        "outputId": "4ec9b1a7-8e1d-4c75-a0bf-0349c1d9257d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-01f66f11-1aad-46fb-83ed-b6f4baa4a7ae\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I went and saw this movie last night after bei...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>As a recreational golfer with some knowledge o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>I saw this film on September 1st, 2005 in Indi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Maybe I'm reading into this too much, but I wo...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>I felt this film did have many good qualities....</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>This movie is amazing because the fact that th...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>\"Quitting\" may be as much about exiting a pre-...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>I loved this movie from beginning to end.I am ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>I was fortunate to attend the London premier o...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>I first saw this movie on IFC. Which is a grea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>I must say, every time I see this movie, I am ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>My wife is a mental health therapist and we wa...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>I saw this film at the Rotterdam International...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>\"Night of the Hunted\" stars French porn star B...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Even if you're a fan of Jean Rollin's idiosync...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>I was surprised how much I enjoyed this. Sure ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>I went into \"Night of the Hunted\" not knowing ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-01f66f11-1aad-46fb-83ed-b6f4baa4a7ae')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-01f66f11-1aad-46fb-83ed-b6f4baa4a7ae button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-01f66f11-1aad-46fb-83ed-b6f4baa4a7ae');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                               review  sentiment\n",
              "0   I went and saw this movie last night after bei...          1\n",
              "1   Actor turned director Bill Paxton follows up h...          1\n",
              "2   As a recreational golfer with some knowledge o...          1\n",
              "3   I saw this film in a sneak preview, and it is ...          1\n",
              "4   Bill Paxton has taken the true story of the 19...          1\n",
              "5   I saw this film on September 1st, 2005 in Indi...          1\n",
              "6   Maybe I'm reading into this too much, but I wo...          1\n",
              "7   I felt this film did have many good qualities....          1\n",
              "8   This movie is amazing because the fact that th...          1\n",
              "9   \"Quitting\" may be as much about exiting a pre-...          1\n",
              "10  I loved this movie from beginning to end.I am ...          1\n",
              "11  I was fortunate to attend the London premier o...          1\n",
              "12  I first saw this movie on IFC. Which is a grea...          1\n",
              "13  I must say, every time I see this movie, I am ...          1\n",
              "14  My wife is a mental health therapist and we wa...          1\n",
              "15  I saw this film at the Rotterdam International...          1\n",
              "16  \"Night of the Hunted\" stars French porn star B...          1\n",
              "17  Even if you're a fan of Jean Rollin's idiosync...          1\n",
              "18  I was surprised how much I enjoyed this. Sure ...          1\n",
              "19  I went into \"Night of the Hunted\" not knowing ...          1"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.DataFrame()\n",
        "df = pd.read_csv('/content/movie_data.csv')\n",
        "df.head(20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fSP6L0BfaH4Z",
        "outputId": "cb53cf13-3efa-4251-a3fe-d24dfa67ac24"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(50000, 2)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9d8Gd2cHxWkc",
        "outputId": "7067fbfd-67d5-480e-90b0-6e345c0f3ee2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    25000\n",
              "0    25000\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQU9Wa-CNaci",
        "outputId": "f5f29edb-e72e-4912-d59c-57ba5f692d58"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt') # Used for sentence tokenizer\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROxKhMU3KmXG",
        "outputId": "ce94a94c-403a-4e4c-ac5f-95a2605e36d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50000\n",
            "[\"I went and saw this movie last night after being coaxed to by a few friends of mine. I'll admit that I was reluctant to see it because from what I knew of Ashton Kutcher he was only able to do comedy. I was wrong. Kutcher played the character of Jake Fischer very well, and Kevin Costner played Ben Randall with such professionalism. The sign of a good movie is that it can toy with our emotions. This one did exactly that. The entire theater (which was sold out) was overcome by laughter during the first half of the movie, and were moved to tears during the second half. While exiting the theater I not only saw many women in tears, but many full grown men as well, trying desperately not to let anyone see them crying. This movie was great, and I suggest that you go see it before you judge.\", 'Actor turned director Bill Paxton follows up his promising debut, the Gothic-horror \"Frailty\", with this family friendly sports drama about the 1913 U.S. Open where a young American caddy rises from his humble background to play against his Bristish idol in what was dubbed as \"The Greatest Game Ever Played.\" I\\'m no fan of golf, and these scrappy underdog sports flicks are a dime a dozen (most recently done to grand effect with \"Miracle\" and \"Cinderella Man\"), but some how this film was enthralling all the same.<br /><br />The film starts with some creative opening credits (imagine a Disneyfied version of the animated opening credits of HBO\\'s \"Carnivale\" and \"Rome\"), but lumbers along slowly for its first by-the-numbers hour. Once the action moves to the U.S. Open things pick up very well. Paxton does a nice job and shows a knack for effective directorial flourishes (I loved the rain-soaked montage of the action on day two of the open) that propel the plot further or add some unexpected psychological depth to the proceedings. There\\'s some compelling character development when the British Harry Vardon is haunted by images of the aristocrats in black suits and top hats who destroyed his family cottage as a child to make way for a golf course. He also does a good job of visually depicting what goes on in the players\\' heads under pressure. Golf, a painfully boring sport, is brought vividly alive here. Credit should also be given the set designers and costume department for creating an engaging period-piece atmosphere of London and Boston at the beginning of the twentieth century.<br /><br />You know how this is going to end not only because it\\'s based on a true story but also because films in this genre follow the same template over and over, but Paxton puts on a better than average show and perhaps indicates more talent behind the camera than he ever had in front of it. Despite the formulaic nature, this is a nice and easy film to root for that deserves to find an audience.', 'As a recreational golfer with some knowledge of the sport\\'s history, I was pleased with Disney\\'s sensitivity to the issues of class in golf in the early twentieth century. The movie depicted well the psychological battles that Harry Vardon fought within himself, from his childhood trauma of being evicted to his own inability to break that glass ceiling that prevents him from being accepted as an equal in English golf society. Likewise, the young Ouimet goes through his own class struggles, being a mere caddie in the eyes of the upper crust Americans who scoff at his attempts to rise above his standing. <br /><br />What I loved best, however, is how this theme of class is manifested in the characters of Ouimet\\'s parents. His father is a working-class drone who sees the value of hard work but is intimidated by the upper class; his mother, however, recognizes her son\\'s talent and desire and encourages him to pursue his dream of competing against those who think he is inferior.<br /><br />Finally, the golf scenes are well photographed. Although the course used in the movie was not the actual site of the historical tournament, the little liberties taken by Disney do not detract from the beauty of the film. There\\'s one little Disney moment at the pool table; otherwise, the viewer does not really think Disney. The ending, as in \"Miracle,\" is not some Disney creation, but one that only human history could have written.', \"I saw this film in a sneak preview, and it is delightful. The cinematography is unusually creative, the acting is good, and the story is fabulous. If this movie does not do well, it won't be because it doesn't deserve to. Before this film, I didn't realize how charming Shia Lebouf could be. He does a marvelous, self-contained, job as the lead. There's something incredibly sweet about him, and it makes the movie even better. The other actors do a good job as well, and the film contains moments of really high suspense, more than one might expect from a movie about golf. Sports movies are a dime a dozen, but this one stands out. <br /><br />This is one I'd recommend to anyone.\", 'Bill Paxton has taken the true story of the 1913 US golf open and made a film that is about much more than an extra-ordinary game of golf. The film also deals directly with the class tensions of the early twentieth century and touches upon the profound anti-Catholic prejudices of both the British and American establishments. But at heart the film is about that perennial favourite of triumph against the odds.<br /><br />The acting is exemplary throughout. Stephen Dillane is excellent as usual, but the revelation of the movie is Shia LaBoeuf who delivers a disciplined, dignified and highly sympathetic performance as a working class Franco-Irish kid fighting his way through the prejudices of the New England WASP establishment. For those who are only familiar with his slap-stick performances in \"Even Stevens\" this demonstration of his maturity is a delightful surprise. And Josh Flitter as the ten year old caddy threatens to steal every scene in which he appears.<br /><br />A old fashioned movie in the best sense of the word: fine acting, clear directing and a great story that grips to the end - the final scene an affectionate nod to Casablanca is just one of the many pleasures that fill a great movie.']\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "review_lines = list()\n",
        "lines = df['review'].values.tolist()\n",
        "print(len(lines))\n",
        "print(lines[:5])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2x1rfkkxq4T"
      },
      "outputs": [],
      "source": [
        "for line in lines:\n",
        "    tokens = word_tokenize(line)\n",
        "    # convert to lower case\n",
        "    tokens = [w.lower() for w in tokens]\n",
        "\n",
        "    # remove punctuation from each word\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    #Replace the characters in the first argument with the corresponding characters in the second argument\n",
        "    #Third argument represents a string of characters that must be removed from the original string\n",
        "    stripped = [w.translate(table) for w in tokens]\n",
        "\n",
        "    # remove remaining tokens that are not alphabetic\n",
        "    words = [word for word in stripped if word.isalpha()] #.isalpha returns True if the chaarcters are aphabets\n",
        "\n",
        "    # filter out stop words\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    words = [w for w in words if not w in stop_words]\n",
        "    review_lines.append(words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZFTILtaKmXH",
        "outputId": "9b034ddb-7d25-4c4d-c5f8-818fdf6ddd89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vocabulary size: 133264\n"
          ]
        }
      ],
      "source": [
        "import gensim # Process plain text\n",
        "\n",
        "EMBEDDING_DIM = 100\n",
        "# train word2vec model\n",
        "model = gensim.models.Word2Vec(sentences=review_lines, size=EMBEDDING_DIM, window=5, min_count=1, sg=0)\n",
        "'''\n",
        "size : Number of dimensions of the embeddings\n",
        "window : sliding window size\n",
        "min_count : Minimum count of words to consider while training a model. Default is 5\n",
        "sg : if you want to use cbow(when 0) or sg(when 1)\n",
        "'''\n",
        "# vocab size\n",
        "words = list(model.wv.vocab) # wv is the object that contain mappings between words and embeddings\n",
        "print('Vocabulary size: %d' % len(words))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jOypRFtxzwqg",
        "outputId": "fd0bd3ee-256f-4b29-8c64-d5ed394acc4c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model['man']\n",
        "len(model['man'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "sdiSMyOrKmXH"
      },
      "outputs": [],
      "source": [
        "# save model in ASCII (word2vec) format\n",
        "filename = 'imdb_embedding_word2vec.txt'\n",
        "model.wv.save_word2vec_format(filename, binary=False) # Don't want to store it in binary format. Default : binary format to save space"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiNZ0eoXKmXI",
        "outputId": "375c52be-7391-467a-e708-c18c248bc6ba"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('cash', 0.6613119840621948),\n",
              " ('deductments', 0.6331372261047363),\n",
              " ('cost', 0.6210497617721558),\n",
              " ('ticket', 0.6172667145729065),\n",
              " ('bucks', 0.6131108403205872),\n",
              " ('bobbitt', 0.6072616577148438),\n",
              " ('bills', 0.6017158627510071),\n",
              " ('paid', 0.5984830260276794),\n",
              " ('desposal', 0.5893391370773315),\n",
              " ('dough', 0.5821436643600464)]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# let us try some utility functions of gensim word2vec more details here\n",
        "\n",
        "model.wv.most_similar('money')#, topn =1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTLSD7G9KmXI",
        "outputId": "52561877-3a72-48aa-db08-571338ffc3f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('princess', 0.7310706377029419)]"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Let’s see the result of semantically reasonable word vectors (king - man + woman)\n",
        "model.wv.most_similar(positive=['queen', 'boy'], negative=['girl'], topn=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVE7mOhYKmXJ",
        "outputId": "2cdbc779-cf36-4907-dbe6-a758065370dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "movie\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/keyedvectors.py:895: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
            "  vectors = vstack(self.word_vec(word, use_norm=True) for word in used_words).astype(REAL)\n"
          ]
        }
      ],
      "source": [
        "#odd word out\n",
        "print(model.wv.doesnt_match(\"woman king queen movie\".split()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QxD6ii5rKmXJ",
        "outputId": "1e814f33-8b6e-4da5-f879-b6b04274a8ca"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('dog', 0.7910478115081787),\n",
              " ('mouse', 0.7626219391822815),\n",
              " ('monkey', 0.7270614504814148),\n",
              " ('bugs', 0.7208654284477234),\n",
              " ('dude', 0.7198402881622314),\n",
              " ('hat', 0.7099525928497314),\n",
              " ('pet', 0.6968947649002075),\n",
              " ('snake', 0.6838912963867188),\n",
              " ('daffy', 0.6773809194564819),\n",
              " ('bird', 0.6726865768432617)]"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.wv.similar_by_word(\"cat\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rihXEcn5KmXJ",
        "outputId": "1c808004-436d-4ec8-c989-30ef9437d556"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.8495133\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "print(model.similarity('boy', 'girl'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "S5mC_7-4KmXJ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "embeddings_index = {}\n",
        "#f = open(os.path.join('', 'imdb_embedding_word2vec.txt'),  encoding = \"utf-8\")\n",
        "f = open('/content/imdb_embedding_word2vec.txt')\n",
        "for line in f:\n",
        "  print(line)\n",
        "  values = line.split()\n",
        "  #print(values)\n",
        "  word = values[0]\n",
        "  coefs = np.asarray(values[1:])\n",
        "  embeddings_index[word] = coefs\n",
        "\n",
        "f.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "vbpuIKvrBsoP",
        "outputId": "e2c65f5b-9842-4739-d5b1-8d3063395ea3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "133265"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(embeddings_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "L68AFRRrKmXK"
      },
      "outputs": [],
      "source": [
        "max_length = 100 # try other options like mean of sentence lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nE33QeEiKmXK"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "# vectorize the text samples into a 2D integer tensor\n",
        "tokenizer_obj = Tokenizer()\n",
        "tokenizer_obj.fit_on_texts(review_lines)\n",
        "sequences = tokenizer_obj.texts_to_sequences(review_lines) # Transforms text into a sequence of integers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Ci6vPC9jh5n"
      },
      "outputs": [],
      "source": [
        "sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n0WrRN_yBWiG"
      },
      "outputs": [],
      "source": [
        "# pad sequences\n",
        "'''\n",
        "pad_sequences : convert a list of sequences into a 2D numpy array of shape (num_samples,num_timesteps)\n",
        "num_timesteps : maxlen(if provided) or length of the longest sequence\n",
        "pre padding or truncating from the beginning is the default, can change it to post\n",
        "'''\n",
        "word_index = tokenizer_obj.word_index # Maps words to their numeric representation\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "vocab_size=len(word_index)+1\n",
        "print('The vocabulary size is: ', vocab_size)\n",
        "review_pad = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
        "sentiment =  df['sentiment'].values\n",
        "print('Shape of review tensor:', review_pad.shape)\n",
        "print('Shape of sentiment tensor:', sentiment.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FLscZdVeBct8",
        "outputId": "56eda4b2-273c-4129-a9a6-3ceb683a889c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[15737 29712 97733 ... 93545 19407 96488]\n"
          ]
        }
      ],
      "source": [
        "# split the data into a training set and a validation set\n",
        "indices = np.arange(review_pad.shape[0])\n",
        "#print(indices)\n",
        "#print(len(indices))\n",
        "np.random.shuffle(indices)\n",
        "print(indices)\n",
        "#print(len(indices))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Gcrmee2CWdh"
      },
      "outputs": [],
      "source": [
        "review_pad = review_pad[indices]\n",
        "sentiment = sentiment[indices]\n",
        "num_validation_samples = int(VALIDATION_SPLIT * review_pad.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wu9PEQaQCSLs"
      },
      "outputs": [],
      "source": [
        "X_train_pad = review_pad[:-num_validation_samples]\n",
        "y_train = sentiment[:-num_validation_samples]\n",
        "X_test_pad = review_pad[-num_validation_samples:]\n",
        "y_test = sentiment[-num_validation_samples:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "85gknMnHKmXK",
        "outputId": "74626e09-8a6f-43d8-d523-058ee4e3a3d1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape of X_train_pad tensor: (40000, 100)\n",
            "Shape of y_train tensor: (40000,)\n",
            "Shape of X_test_pad tensor: (10000, 100)\n",
            "Shape of y_test tensor: (10000,)\n"
          ]
        }
      ],
      "source": [
        "print('Shape of X_train_pad tensor:', X_train_pad.shape)\n",
        "print('Shape of y_train tensor:', y_train.shape)\n",
        "\n",
        "print('Shape of X_test_pad tensor:', X_test_pad.shape)\n",
        "print('Shape of y_test tensor:', y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "9i2VTYzYKmXK"
      },
      "outputs": [],
      "source": [
        "EMBEDDING_DIM =100\n",
        "embedding_matrix = np.zeros((vocab_size, EMBEDDING_DIM))\n",
        "\n",
        "for word, i in word_index.items():\n",
        "  embedding_vector = embeddings_index.get(word) #model[word]\n",
        "  if embedding_vector is not None:\n",
        "    # words not found in embedding index will be all-zeros.\n",
        "    embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5j_NBP_MKmXM",
        "outputId": "9b37d50a-87ed-4493-c911-ee436e3af972"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Summary of the built model...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 100, 100)          13326500  \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 32)                17024     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 33        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,343,557\n",
            "Trainable params: 17,057\n",
            "Non-trainable params: 13,326,500\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import tensorflow\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding, LSTM, GRU\n",
        "from tensorflow.keras.initializers import Constant\n",
        "\n",
        "# define model\n",
        "model = Sequential()\n",
        "embedding_layer = Embedding(vocab_size,\n",
        "                            EMBEDDING_DIM,\n",
        "                            embeddings_initializer=Constant(embedding_matrix),\n",
        "                            input_length=max_length,\n",
        "                            trainable=False)\n",
        "model.add(embedding_layer)\n",
        "model.add(LSTM(units=32,  dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# try using different optimizers and different optimizer configs\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "print('Summary of the built model...')\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QyBy9GNdKmXM",
        "outputId": "3544262e-3f2a-40cf-fb79-017714f2dc1d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Epoch 1/50\n",
            "313/313 - 118s - loss: 0.5168 - accuracy: 0.7525 - val_loss: 0.4282 - val_accuracy: 0.8162 - 118s/epoch - 376ms/step\n",
            "Epoch 2/50\n",
            "313/313 - 108s - loss: 0.4007 - accuracy: 0.8260 - val_loss: 0.3705 - val_accuracy: 0.8430 - 108s/epoch - 346ms/step\n",
            "Epoch 3/50\n",
            "313/313 - 109s - loss: 0.3580 - accuracy: 0.8447 - val_loss: 0.3351 - val_accuracy: 0.8549 - 109s/epoch - 349ms/step\n",
            "Epoch 4/50\n",
            "313/313 - 108s - loss: 0.3383 - accuracy: 0.8544 - val_loss: 0.3234 - val_accuracy: 0.8633 - 108s/epoch - 345ms/step\n",
            "Epoch 5/50\n",
            "313/313 - 107s - loss: 0.3223 - accuracy: 0.8637 - val_loss: 0.3144 - val_accuracy: 0.8668 - 107s/epoch - 342ms/step\n",
            "Epoch 6/50\n",
            "313/313 - 108s - loss: 0.3144 - accuracy: 0.8655 - val_loss: 0.3121 - val_accuracy: 0.8669 - 108s/epoch - 345ms/step\n",
            "Epoch 7/50\n",
            "313/313 - 107s - loss: 0.3046 - accuracy: 0.8707 - val_loss: 0.3063 - val_accuracy: 0.8693 - 107s/epoch - 343ms/step\n",
            "Epoch 8/50\n",
            "313/313 - 109s - loss: 0.3038 - accuracy: 0.8693 - val_loss: 0.3000 - val_accuracy: 0.8730 - 109s/epoch - 347ms/step\n",
            "Epoch 9/50\n",
            "313/313 - 108s - loss: 0.2939 - accuracy: 0.8751 - val_loss: 0.2933 - val_accuracy: 0.8721 - 108s/epoch - 345ms/step\n",
            "Epoch 10/50\n",
            "313/313 - 109s - loss: 0.2889 - accuracy: 0.8756 - val_loss: 0.3113 - val_accuracy: 0.8698 - 109s/epoch - 348ms/step\n",
            "Epoch 11/50\n",
            "313/313 - 107s - loss: 0.2854 - accuracy: 0.8799 - val_loss: 0.2888 - val_accuracy: 0.8738 - 107s/epoch - 341ms/step\n",
            "Epoch 12/50\n",
            "313/313 - 109s - loss: 0.2788 - accuracy: 0.8813 - val_loss: 0.3097 - val_accuracy: 0.8667 - 109s/epoch - 349ms/step\n",
            "Epoch 13/50\n",
            "313/313 - 108s - loss: 0.2799 - accuracy: 0.8819 - val_loss: 0.2904 - val_accuracy: 0.8739 - 108s/epoch - 344ms/step\n",
            "Epoch 14/50\n",
            "313/313 - 109s - loss: 0.2739 - accuracy: 0.8849 - val_loss: 0.2958 - val_accuracy: 0.8776 - 109s/epoch - 347ms/step\n",
            "Epoch 15/50\n",
            "313/313 - 107s - loss: 0.2736 - accuracy: 0.8845 - val_loss: 0.2892 - val_accuracy: 0.8767 - 107s/epoch - 343ms/step\n",
            "Epoch 16/50\n",
            "313/313 - 108s - loss: 0.2678 - accuracy: 0.8885 - val_loss: 0.2847 - val_accuracy: 0.8782 - 108s/epoch - 345ms/step\n",
            "Epoch 17/50\n",
            "313/313 - 108s - loss: 0.2639 - accuracy: 0.8892 - val_loss: 0.2917 - val_accuracy: 0.8738 - 108s/epoch - 344ms/step\n",
            "Epoch 18/50\n",
            "313/313 - 106s - loss: 0.2612 - accuracy: 0.8902 - val_loss: 0.2889 - val_accuracy: 0.8790 - 106s/epoch - 338ms/step\n",
            "Epoch 19/50\n",
            "313/313 - 107s - loss: 0.2592 - accuracy: 0.8918 - val_loss: 0.2862 - val_accuracy: 0.8773 - 107s/epoch - 342ms/step\n",
            "Epoch 20/50\n",
            "313/313 - 106s - loss: 0.2578 - accuracy: 0.8913 - val_loss: 0.2914 - val_accuracy: 0.8796 - 106s/epoch - 339ms/step\n",
            "Epoch 21/50\n",
            "313/313 - 107s - loss: 0.2555 - accuracy: 0.8931 - val_loss: 0.2927 - val_accuracy: 0.8789 - 107s/epoch - 343ms/step\n",
            "Epoch 22/50\n",
            "313/313 - 105s - loss: 0.2536 - accuracy: 0.8959 - val_loss: 0.2889 - val_accuracy: 0.8809 - 105s/epoch - 336ms/step\n",
            "Epoch 23/50\n",
            "313/313 - 107s - loss: 0.2526 - accuracy: 0.8940 - val_loss: 0.2947 - val_accuracy: 0.8817 - 107s/epoch - 342ms/step\n",
            "Epoch 24/50\n",
            "313/313 - 106s - loss: 0.2501 - accuracy: 0.8955 - val_loss: 0.2842 - val_accuracy: 0.8817 - 106s/epoch - 338ms/step\n",
            "Epoch 25/50\n",
            "313/313 - 106s - loss: 0.2491 - accuracy: 0.8970 - val_loss: 0.2877 - val_accuracy: 0.8807 - 106s/epoch - 337ms/step\n",
            "Epoch 26/50\n",
            "313/313 - 106s - loss: 0.2471 - accuracy: 0.8978 - val_loss: 0.2826 - val_accuracy: 0.8809 - 106s/epoch - 338ms/step\n",
            "Epoch 27/50\n",
            "313/313 - 106s - loss: 0.2438 - accuracy: 0.8992 - val_loss: 0.2954 - val_accuracy: 0.8758 - 106s/epoch - 337ms/step\n",
            "Epoch 28/50\n",
            "313/313 - 106s - loss: 0.2385 - accuracy: 0.9007 - val_loss: 0.2862 - val_accuracy: 0.8813 - 106s/epoch - 340ms/step\n",
            "Epoch 29/50\n",
            "313/313 - 106s - loss: 0.2429 - accuracy: 0.8986 - val_loss: 0.2842 - val_accuracy: 0.8813 - 106s/epoch - 339ms/step\n",
            "Epoch 30/50\n",
            "313/313 - 107s - loss: 0.2391 - accuracy: 0.9016 - val_loss: 0.2914 - val_accuracy: 0.8800 - 107s/epoch - 342ms/step\n",
            "Epoch 31/50\n",
            "313/313 - 106s - loss: 0.2389 - accuracy: 0.9010 - val_loss: 0.2904 - val_accuracy: 0.8818 - 106s/epoch - 339ms/step\n",
            "Epoch 32/50\n",
            "313/313 - 106s - loss: 0.2356 - accuracy: 0.9021 - val_loss: 0.2914 - val_accuracy: 0.8818 - 106s/epoch - 340ms/step\n",
            "Epoch 33/50\n",
            "313/313 - 107s - loss: 0.2343 - accuracy: 0.9031 - val_loss: 0.3038 - val_accuracy: 0.8792 - 107s/epoch - 343ms/step\n",
            "Epoch 34/50\n",
            "313/313 - 105s - loss: 0.2366 - accuracy: 0.9014 - val_loss: 0.2898 - val_accuracy: 0.8791 - 105s/epoch - 337ms/step\n",
            "Epoch 35/50\n",
            "313/313 - 107s - loss: 0.2341 - accuracy: 0.9031 - val_loss: 0.2873 - val_accuracy: 0.8749 - 107s/epoch - 341ms/step\n",
            "Epoch 36/50\n",
            "313/313 - 105s - loss: 0.2298 - accuracy: 0.9059 - val_loss: 0.3038 - val_accuracy: 0.8767 - 105s/epoch - 336ms/step\n",
            "Epoch 37/50\n",
            "313/313 - 106s - loss: 0.2292 - accuracy: 0.9052 - val_loss: 0.2943 - val_accuracy: 0.8790 - 106s/epoch - 338ms/step\n",
            "Epoch 38/50\n",
            "313/313 - 106s - loss: 0.2305 - accuracy: 0.9048 - val_loss: 0.2955 - val_accuracy: 0.8768 - 106s/epoch - 340ms/step\n",
            "Epoch 39/50\n",
            "313/313 - 105s - loss: 0.2283 - accuracy: 0.9052 - val_loss: 0.3024 - val_accuracy: 0.8796 - 105s/epoch - 337ms/step\n",
            "Epoch 40/50\n",
            "313/313 - 107s - loss: 0.2283 - accuracy: 0.9072 - val_loss: 0.2873 - val_accuracy: 0.8782 - 107s/epoch - 342ms/step\n",
            "Epoch 41/50\n",
            "313/313 - 106s - loss: 0.2267 - accuracy: 0.9075 - val_loss: 0.3063 - val_accuracy: 0.8753 - 106s/epoch - 338ms/step\n",
            "Epoch 42/50\n",
            "313/313 - 105s - loss: 0.2232 - accuracy: 0.9081 - val_loss: 0.3070 - val_accuracy: 0.8807 - 105s/epoch - 334ms/step\n",
            "Epoch 43/50\n",
            "313/313 - 107s - loss: 0.2249 - accuracy: 0.9071 - val_loss: 0.2980 - val_accuracy: 0.8791 - 107s/epoch - 341ms/step\n",
            "Epoch 44/50\n",
            "313/313 - 106s - loss: 0.2242 - accuracy: 0.9075 - val_loss: 0.3040 - val_accuracy: 0.8805 - 106s/epoch - 337ms/step\n",
            "Epoch 45/50\n",
            "313/313 - 106s - loss: 0.2212 - accuracy: 0.9093 - val_loss: 0.3091 - val_accuracy: 0.8805 - 106s/epoch - 338ms/step\n",
            "Epoch 46/50\n",
            "313/313 - 105s - loss: 0.2226 - accuracy: 0.9094 - val_loss: 0.3162 - val_accuracy: 0.8771 - 105s/epoch - 336ms/step\n",
            "Epoch 47/50\n",
            "313/313 - 106s - loss: 0.2227 - accuracy: 0.9101 - val_loss: 0.3198 - val_accuracy: 0.8654 - 106s/epoch - 338ms/step\n",
            "Epoch 48/50\n",
            "313/313 - 107s - loss: 0.2247 - accuracy: 0.9083 - val_loss: 0.3012 - val_accuracy: 0.8783 - 107s/epoch - 341ms/step\n",
            "Epoch 49/50\n",
            "313/313 - 104s - loss: 0.2208 - accuracy: 0.9093 - val_loss: 0.3150 - val_accuracy: 0.8817 - 104s/epoch - 334ms/step\n",
            "Epoch 50/50\n",
            "313/313 - 106s - loss: 0.2180 - accuracy: 0.9118 - val_loss: 0.2932 - val_accuracy: 0.8801 - 106s/epoch - 338ms/step\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fbdceed52d0>"
            ]
          },
          "execution_count": 43,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print('Train...')\n",
        "\n",
        "model.fit(X_train_pad, y_train, batch_size=128, epochs=50, validation_data=(X_test_pad, y_test), verbose=2)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}